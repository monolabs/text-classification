{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "249dac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.getcwd() + '/../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95e7cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scripts.bert_utils import *\n",
    "\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf4a7cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>d'aww ! he match this background colour i be s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>hey man , i be really not try to edit war . it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>`` more i can not make any real suggestion on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>you , sir , be my hero . any chance you rememb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic                                       comment_text\n",
       "0      0  explanation why the edits make under my userna...\n",
       "1      0  d'aww ! he match this background colour i be s...\n",
       "2      0  hey man , i be really not try to edit war . it...\n",
       "3      0  `` more i can not make any real suggestion on ...\n",
       "4      0  you , sir , be my hero . any chance you rememb..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = pd.read_csv('data/comments/preprocessed_comments.csv', index_col=0)\n",
    "comments = comments.dropna()\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb241615",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_text, test_text, temp_labels, test_labels = train_test_split(comments['comment_text'], \n",
    "                                                                  comments['toxic'], \n",
    "                                                                  random_state=0, \n",
    "                                                                  test_size=0.2, \n",
    "                                                                  stratify=comments['toxic'])\n",
    "\n",
    "\n",
    "train_text, val_text, train_labels, val_labels = train_test_split(temp_text, \n",
    "                                                                  temp_labels, \n",
    "                                                                  random_state=0, \n",
    "                                                                  test_size=0.2, \n",
    "                                                                  stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e82a9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d51784a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1000.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_len = [len(i.split()) for i in train_text]\n",
    "plt.hist(seq_len, bins=100)\n",
    "plt.vlines(256, 0, 60000, linestyles='dotted', color='k')\n",
    "plt.xlim(0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28f6d893",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens = 128\n",
    "\n",
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = n_tokens,\n",
    "    padding='max_length',\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = n_tokens,\n",
    "    padding='max_length',\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = n_tokens,\n",
    "    padding='max_length',\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b63c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert lists to tensors\n",
    "\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b0ce873",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "      \n",
    "        super(BERT_Arch, self).__init__()\n",
    "\n",
    "        self.bert = bert \n",
    "      \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "      \n",
    "        # relu activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "\n",
    "        # dense layer 1\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "      \n",
    "        # dense layer 2 (Output layer)\n",
    "        self.fc2 = nn.Linear(512,2)\n",
    "\n",
    "        #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "        #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "\n",
    "        #pass the inputs to the model  \n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "      \n",
    "        x = self.fc1(cls_hs)\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # output layer\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "  \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62a42d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b853d2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path = 'models/bert_v1.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d60ec78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting batch 1 of 256\n",
      "predicting batch 20 of 256\n",
      "predicting batch 40 of 256\n",
      "predicting batch 60 of 256\n",
      "predicting batch 80 of 256\n",
      "predicting batch 100 of 256\n",
      "predicting batch 120 of 256\n",
      "predicting batch 140 of 256\n",
      "predicting batch 160 of 256\n",
      "predicting batch 180 of 256\n",
      "predicting batch 200 of 256\n",
      "predicting batch 220 of 256\n",
      "predicting batch 240 of 256\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# get predictions for test data in batch\n",
    "\n",
    "batch_size = 100\n",
    "n_batch = math.ceil(len(val_seq)/batch_size)\n",
    "\n",
    "preds = []\n",
    "for b in range(n_batch):\n",
    "    \n",
    "    if (b+1)%20 == 0 or b==0:\n",
    "        print(f\"predicting batch {b+1} of {n_batch}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = model(val_seq[b*batch_size:(b+1)*batch_size].to(device), \n",
    "                     val_mask[b*batch_size:(b+1)*batch_size].to(device))\n",
    "        pred = pred.detach().cpu()\n",
    "        preds.append(pred)\n",
    "    \n",
    "preds = torch.cat(preds)\n",
    "preds = preds.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee2750ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93     23085\n",
      "           1       0.44      0.81      0.57      2447\n",
      "\n",
      "    accuracy                           0.88     25532\n",
      "   macro avg       0.71      0.85      0.75     25532\n",
      "weighted avg       0.93      0.88      0.90     25532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(val_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ec3f9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BERT v1</th>\n",
       "      <td>0.883675</td>\n",
       "      <td>0.441407</td>\n",
       "      <td>0.805067</td>\n",
       "      <td>0.570188</td>\n",
       "      <td>0.848538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         accuracy  precision    recall        f1   roc_auc\n",
       "BERT v1  0.883675   0.441407  0.805067  0.570188  0.848538"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_evaluation_df(val_y, preds, 'BERT v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066e24ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (transformers)",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
